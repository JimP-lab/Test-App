<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AI Face Generation & Identifier</title>

    <!-- Load AI Models -->
    <script defer src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/face-api.js"></script>

    <style>
        body {
            font-family: Arial, sans-serif;
            text-align: center;
            background-color: #f4f4f4;
        }
        .container {
            display: flex;
            justify-content: center;
            align-items: center;
            height: 90vh;
        }
        .panel {
            flex: 1;
            padding: 20px;
            border-radius: 10px;
            background: white;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
            margin: 10px;
        }
        .left-panel {
            text-align: center;
        }
        video, img {
            width: 100%;
            max-width: 400px;
            border-radius: 10px;
            border: 2px solid #ddd;
        }
        .threat-safe {
            color: green;
            font-weight: bold;
        }
        .threat-danger {
            color: red;
            font-weight: bold;
        }
        button {
            margin-top: 10px;
            padding: 10px;
            font-size: 16px;
            cursor: pointer;
            background-color: blue;
            color: white;
            border: none;
            border-radius: 5px;
        }
        button:hover {
            background-color: darkblue;
        }
    </style>
</head>
<body>

    <h1>AI Face Generation & Identifier</h1>
    <div class="container">
        <!-- Left Panel: Live Camera -->
        <div class="panel left-panel">
            <h2>Live Camera</h2>
            <video id="video" autoplay style="display:none;"></video>
            <button id="scan-button">Start Scanning</button>
        </div>

        <!-- Middle Panel: AI-Generated Person -->
        <div class="panel left-panel">
            <h2>AI-Generated Person</h2>
            <canvas id="captured-face" style="display:none;"></canvas>
            <img id="generated-image" src="" alt="AI Generated Face" style="display:none;">
        </div>

        <!-- Right Panel: Identity & Threat Detection -->
        <div class="panel right-panel">
            <h2>Identified Person</h2>
            <p><b>Name:</b> <span id="name">Waiting for scan...</span></p>
            <p><b>Age:</b> <span id="age">--</span></p>
            <p><b>ID:</b> <span id="id_number">--</span></p>
            <p><b>Threat Level:</b> <span id="threat-level" class="threat-safe">--</span></p>
        </div>
    </div>

    <script>
        const video = document.getElementById('video');
        const scanButton = document.getElementById('scan-button');
        const nameDisplay = document.getElementById('name');
        const ageDisplay = document.getElementById('age');
        const idDisplay = document.getElementById('id_number');
        const threatDisplay = document.getElementById('threat-level');
        const generatedImage = document.getElementById('generated-image');
        const capturedCanvas = document.getElementById('captured-face');
        const ctx = capturedCanvas.getContext('2d');

        let cameraStarted = false;

        // Load Face API Models
        async function loadModels() {
            await faceapi.nets.tinyFaceDetector.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models');
            await faceapi.nets.faceRecognitionNet.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models');
            await faceapi.nets.faceLandmark68Net.loadFromUri('https://cdn.jsdelivr.net/npm/face-api.js/models');
            console.log("AI Models Loaded!");
        }

        // Start Camera Only When Clicking the Button
        async function startVideo() {
            if (!cameraStarted) {
                navigator.mediaDevices.getUserMedia({ video: {} })
                    .then(stream => {
                        video.srcObject = stream;
                        video.style.display = "block"; // Show video
                        cameraStarted = true;
                    })
                    .catch(err => console.error("Error accessing webcam:", err));
            }
        }

        // Capture Face from Camera
        async function captureFace() {
            capturedCanvas.width = video.videoWidth;
            capturedCanvas.height = video.videoHeight;
            ctx.drawImage(video, 0, 0, capturedCanvas.width, capturedCanvas.height);
            return capturedCanvas.toDataURL(); // Convert to image data URL
        }

        // Generate AI Image from Captured Face (Simulated)
        async function generateAIImage(imageData) {
            console.log("Generating AI Image from Captured Face...");
            
            // Here, normally an API call like OpenAI's DALLÂ·E would be used
            // For now, let's use a test placeholder instead
            generatedImage.src = imageData; // Simulated output
            generatedImage.style.display = "block";
        }

        // Scan Face and Identify (Triggered by Button)
        async function scanFace() {
            if (!cameraStarted) {
                alert("Please allow camera access first!");
                return;
            }

            const detections = await faceapi.detectAllFaces(video, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptors();

            if (detections.length > 0) {
                console.log("Face Detected!");

                // Capture face image from camera
                const capturedImage = await captureFace();

                // Simulate AI image generation
                await generateAIImage(capturedImage);

                // Simulated Identity Recognition
                nameDisplay.innerText = "Person Identified";
                ageDisplay.innerText = "Unknown";
                idDisplay.innerText = "Scanning...";
                threatDisplay.innerText = "Safe";
                threatDisplay.className = "threat-safe";

            } else {
                alert("No face detected. Try again.");
            }
        }

        // Start Face API Models
        loadModels();

        // Attach event listener to scan button
        scanButton.addEventListener("click", async () => {
            if (!cameraStarted) {
                await startVideo(); // Open camera when clicked
            } else {
                await scanFace(); // Start scanning if camera is already on
            }
        });

    </script>

</body>
</html>
